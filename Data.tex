\section{Original Source}
Constructing the final dataset of SCA lawsuits proved to be a quite verbose procedure requesting mapping data from different sources. This section will articulate the sources, the cleaning process as well as the construction of dataset.
Firstly, main actions adopted from Hiscox are elaborated below.  
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\thead{General Adjustments} & \thead{Justification } \\
\hline
\makecell{Companies outside the\\ U.S are removed} & \makecell{The model will only be utilised for \\U.S. Incorporated Public companies}\\
\hline
\makecell{Claims not insurable or excluded\\ from D\&O Policy removed} & \makecell{The remained claims are \\more connected to D\&O claims}\\
\hline
\makecell{Companies traded on OTC removed } & \makecell{SCA dynamics are materially \\different for OTC traded companies}\\
\hline
\makecell{Additional Claims fields added} & \makecell{100\% of these amounts are covered as a \\Claim by the D\&O Policy}\\
\hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[H]
\begin{center}
\begin{tabular}{ | c  | c |}
\hline
\multicolumn{2}{|c|}{\thead{Feature Description}}\\
\hline
\rowcolor{Gray}
Entity Name & Company named in lawsuit, not unique\\
\hline
Case Number & Lawsuit Case Number\\
\hline
\rowcolor{Gray}
CUSIP & An acronym used to identify securities\\
\hline
SIC & Four-digit code used to classify industry\\
\hline
\rowcolor{Gray}
Sector Number & Industry segments, details see appendix\\
\hline
SCA Description & Summary of the main reason of SCA\\
\hline
\rowcolor{Gray}
SCA Category &Subjective 12 different categories by description\\
\hline
Different Date & \makecell{Class Period Start Date; Class Period End Date\\Suit Date; Settlement Date}\\
\hline
\rowcolor{Gray}
Disposition & Status of SCA: Dismissed, Settled and Open\\
\hline
Cash Settlement Amount & Amount case settled for only for cases settled\\
\hline
\rowcolor{Gray}
Market Cap & Market cap as of Date of Class Period Start Date\\
\hline
Market Cap Band & Grouped Market Cap into 12 bins\\
\hline
\rowcolor{Gray}
Stock Price-Open & Stock Price as of Date of Class Period Start Date\\
\hline
Stock Price-3 Weeks Prior & 3 weeks prior to the Class Period End Date\\
\hline
\rowcolor{Gray}
Stock Price-Close & Date of Class Period End Date plus one day\\
\hline
Shares Outstanding & Date of Class Period Start Date\\
\hline
\rowcolor{Gray}
Pctg Increase, Decrease & Calculated by Stock Price\\
\hline
Market Value Drop & Woodruff coded this value from Bloomberg\\
\hline
\rowcolor{Gray}
Insider Holding Percentage & \% held by insiders\\
\hline
MCap-No Insider Holdings & Market Cap excluded insider part\\
\hline
\rowcolor{Gray}
Mkt Value Drop-No Insider & Market Value Drop excluded insider part\\
\hline
Financial Numbers & Revenue, Profits, Assets, Net Worth\\
\hline
\rowcolor{Gray}
Finanical Ratios & \makecell{P/E Ratio, MCap to Net Worth, Profit to Revenue\\ Profit to Asset, Profit to Net Worth\\Derived from the Company Financial end Year\\ subsequent to the Class Period Start Date}\\
\hline
Court & Generally the state and location of court district\\
\hline
\rowcolor{Gray}
Ticker & Ticker changes over time\\
\hline
Stock Exchange & AMEX, OTC BB, NYSE, NASDAQ, OTHERS\\
\hline
\rowcolor{Gray}
Hdqtr State & US states where the company based \\
\hline
IPO Date, Price & Public company's IPO information\\
\hline
\rowcolor{Gray}
Settlement Remarks & Settlement status description\\
\hline
Bankruptcy & If the company bankrupted or not\\
\hline
\rowcolor{Gray}
Plaintiff Firm and Tier & Subjective judgement for Tier\\
\hline
\end{tabular}
\end{center}
\end{table}
The principal source of data coming from the Hiscox which originated from Woodruff-Sawyer \& Co SCA Database. All features can be described in a table as shown above.

\section{Data Cleansing and Transformation}
\subsection{Data Cleaning}
The adjusted dataset is clean enough with few blanks yet still require some cleaning for future modelling. There are originally 3039 rows. Excel is mainly applied for cleaning process which can be summarised as follows:
\begin{enumerate}
   \item Firstly, we only considered the cases that had a case status "Settled" or "Dismissed", resulting in the removal of 406 rows.(Filter Useless Values)
   \item Secondly, 4 duplicates were deleted in case of modelling error(Duplicates)
   \item Thirdly, those rows with missing values will be deleted or replaced 
   \begin{itemize}
     \item Drop 78 rows with lots of missing financial information 
     \item Rows lack of IPO Price were randomly assign values from 20 to 40 
     \item Delete 127 rows without allegation information 
   \end{itemize}
   \item Finally, check each feature with big outliers, replace them with the mean 
\end{enumerate}
Furthermore, there are a few features generated by original features which can be described below:
 \begin{itemize}
     \item Dependent Binary Variable (Settle or Dismiss) generated by Disposition 
     \item 12 binary variables describing the category of SCA were combined to 1 category variable with number 1 to 12, see Appendix
     \item Class Period Length were calculated by Class Period Start and End Date
     \item Filing Period were days between Class Start Date and Suit Date
     \item Filing Binary were decided by if Filing Period is 0 or not 
     \item Number of Days to Settle, days between Suit Date and Settlement Date
     \item Number of Days went Public, days between IPO Date and Suit Date
     \item Dependent Binary Variable (Settle or Dismiss) generated by Disposition 
     \item Percentage Decrease and Increase were mapped to variable New Percentage Decrease where negative value means percentage increase
     \item Category variable Circuit was manually added derived from feature Court with US Circuit Map as reference, please see \href{http://www.uscourts.gov/about-federal-courts/federal-courts-public/court-website-links}{\hl{Court Website Links}}  
     \item Variable Stock Exchange transformed to quantitative category feature
     \item 29 binary features w.r.t. Allegation Type were mapped in the dataset using unique case ID for predictive modelling, see Appendix
  \end{itemize}
\subsection{Data Transformation}
For the purpose of making all variables under the same measurement as well as getting a better linear relationship and stabilising the variance, we need to standardise or normalise most of our continuous variables. Most used standardisation and normalisation methods are displayed and compared as follows: 
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\rowcolor{Graylight}
Method & Math Operation & Advantage & Disadvantage\\
\hline
Logarithm  & $\ln{x}$ or $\log_{10}x$ & Right skewed data & 0 and negative values\\
\hline
\rowcolor{Gray}
Square root & $\sqrt{x}$ &  Right skewed data & Negative values\\
\hline
Square & $x^2$ & Left skewed data & Negative values\\
\hline
\rowcolor{Gray}
Z-Score & $z=\frac{x-\mu}{\sigma}$ & Negative Values & Depends\\
\hline
Min-Max & $x_{norm}=\frac{x-x_{min}}{x_{max}-x_{min}}$ & preserve range & Depends\\
\hline
\end{tabular}
\end{center}
\end{table}
After take a look of distribution of all continuous variables, we find that most of them are right skewed with long tail. Therefore, we transformed those non-negative variables by minimum value plus 1 and take natural logarithm(to guarantee non-negative values after taking the log). On the other hand, for those features with large negative values such as Net Worth, we simply used Z-Score to standardise them. 

\section{Additional Sources}
\subsection{S\&P 500 Index Data}
In addition to Hiscox data, we also considered S\&P 500 Return over the class period of each company using Yahoo! data which proved to be a important variable for prediction model later. If we define stock price percentage change as company return, then this new variable can act as a benchmark to compare. Start from S\&P 500 Index, we approximated index on weekends as the value of previous day. Then we map the index separately to class start date as well as class end date for each company and finally calculated the corresponding return. This can tell us how the company's return compared to market as a whole during class period. However, a potentially better benchmark might be the returns of similar firms. 
\subsection{Google Data}
As some literatures suggests that case notoriety might be important for predicting cash settlement amounts(Baker and Griffith 2009). Thus it is worth trying to generate a numerical proxy of notoriety by manually via the Google News Archive. Therefore, number of news restricted to one year prior to the filing date with company name plus key words "class action" as input was returned as a new predictor. If we looked at the number of news matches with the same time window but only keep company's name as search term, a high positive correlation 0.84 can be calculated by Excel built in function between previous notoriety and new notoriety. Hence we can neglect the second variable for later modelling. Besides, some companies have 0 Google hits and more importantly, only the number of news pre-filing can be used for prediction. Finally, Google Hits with log form will be put in as a new feature. 

\section{Overview of Tidy Dataset}
After all the processes described above, we prepared our base dataset with 2052 cases for times series forecasting and modelling the probability if a case will be settled. The database of 1172 cases will be used fro predicting amount of total settlement. Thus the latter dataset is a subset of the former one. In this section, let us describe and present summary statistics of our base dataset  to find previously unknown relationships in descriptive part. Firstly, all the features can be generalised by following types. 
\begin{table}[H]
\begin{center}
\begin{tabular}{|c|c|}
\hline
\multicolumn{2}{|c|}{\thead{Main Types of Features}} \\
\hline
\rowcolor{Gray}
Categorical Variable & Continuous Variables \\
\hline
\makecell{Sector Number; \\SCA Category Variable;\\ Market Cap Band; \\Circuit; \\Stock Exchange Category; \\Bankruptcy Binary; \\Filing Binary;\\All Allegation Binary Features} & \makecell{Class Period Length; FilingPeriod; \\Number of Days to Settle; \\Number of Days went Public; \\Cash Settlement Amount; 8 Financial Ratios;\\Market Cap; MCap-No Insider Holdings;\\3 Stock Price Variables; Shares Outstanding; \\ Percentage Decrease; Market Value Drop;\\ Insider Holding Percentage; IPO Price; \\ Mkt Value Drop-No Insider Holdings;\\Google Hits; S\&P Return}\\
\hline
\end{tabular}
\end{center}
\end{table}
Now we can take a look of statistics of main continuous features in the dataset by Box-and-Whisker Plot. Firstly, we can plot those non-negative continuous variables as follows:
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.4]{Positive.png}
  \caption{Box and Whisker Plot of Positive Continuous Features}
\end{figure}
From the plot we can see that 4 time period features, 6 financial features, 3 stock price features are separately distributed into three different measurements. In addition, it is evident that market value drop have some unusual outliers. On the other hand, Revenue, Assets, and Google Hits are in a quite large scope while stock price and period features have a quite narrow range. On the other hand, there are more cases with longer Filing Period than shorter period(top whisker longer than bottom one), yet there are less cases with longer Date to IPO than shorter ones. Now let us take a look on statistics of those features who have negative values. 
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.4]{Negative.png}
  \caption{Box and Whisker Plot of Negative Continuous Features}
\end{figure}
From the above plot, we can see that all percentage variables except Insider Holding Percentage, Stock Price Percentage Decrease, and S\&P 500 Return distributed around 0 with lots of outliers which means they are badly right or left skewed. This may also suggests that they might not be good predictors in future linear modelling. Future exploration of feature relationships in the dataset will be articulated at the first section of the following forecasting and prediction chapter. 